PSEUDO-CODE: chat() function with memory triggers
==================================================

def chat(user_input: str) -> str:
    # Add user message to conversation
    messages.append(HumanMessage(user_input))

    # Get initial LLM response
    response = llm_with_tools.invoke(messages)

    # Add response to messages
    messages.append(response)

    # Track TodoWrite step count for memory trigger
    todo_step_count = 0

    # Track replan
    is_first_time_planning = True
    should_call_replan = False

    # MAIN TOOL EXECUTION LOOP
    while response.tool_calls:
        # TRIGGER memory_recall
        if should_call_replan:
            should_call_replan = false
            message = HumanMessage("Call memory_recall sub-agent to recall memories, and replan using TodoWrite ONLY if needed ")
            messages.append(message)
            response = llm_with_tools.invoke(messages)
            messages.append(response)
        else:
            for tool_call in response.tool_calls:
                tool_name = tool_call["name"]
                tool_args = tool_call["args"]

                # Execute the tool
                tool_result = tools_map[tool_name].invoke(tool_args)

                # Add tool result to messages
                messages.append(ToolMessage(tsool_result, tool_call_id))

                # MEMORY TRIGGER ? Track TodoWrite step count
                if tool_name.lower() == "todowrite" and "todos" in tool_args and is_first_time_planning:
                    todo_step_count = len(tool_args["todos"])
                    is_first_time_planning = False
                    if todo_step_count > N_TASK_THRESHOLD:
                        should_call_replan = True
                
            # Get next LLM response
            response = llm_with_tools.invoke(messages)
            messages.append(response)



    # MEMORY TRIGGER: After loop completes, remind LLM to consider storing learnings
    # LLM decides whether to invoke memory-store agent
    messages.append(
        HumanMessage("Consider storing learnings from this task using memory-store agent if valuable patterns were discovered.")
    )
    response = llm_with_tools.invoke(messages)
    messages.append(response)

    # Return final response content
    return response.content

